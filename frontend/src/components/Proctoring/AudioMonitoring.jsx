import { useState, useEffect, useRef, useCallback } from 'react';\nimport { toast } from 'react-toastify';\n\nconst AudioMonitoring = ({ isActive, onViolation, examId, studentId, securityLevel = 2 }) => {\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const microphoneRef = useRef(null);\n  const animationRef = useRef(null);\n  const audioDataRef = useRef(new Uint8Array());\n  const violationCooldownRef = useRef(new Set());\n  const audioHistoryRef = useRef([]);\n  const voiceDetectionRef = useRef({\n    lastVoiceTime: 0,\n    voiceDuration: 0,\n    silenceDuration: 0,\n    avgAmplitude: 0\n  });\n  \n  const [stream, setStream] = useState(null);\n  const [isInitialized, setIsInitialized] = useState(false);\n  const [audioData, setAudioData] = useState({\n    volume: 0,\n    frequency: 0,\n    isVoiceDetected: false,\n    backgroundNoise: 0,\n    suspiciousActivity: false,\n    voiceCount: 0,\n    silenceLevel: 0\n  });\n  const [violations, setViolations] = useState([]);\n  const [microphonePermission, setMicrophonePermission] = useState('prompt');\n  \n  // Violation types for audio monitoring\n  const VIOLATION_TYPES = {\n    VOICE_DETECTED: 'voice_detected',\n    MULTIPLE_VOICES: 'multiple_voices_detected',\n    SUSPICIOUS_SOUND: 'suspicious_sound',\n    BACKGROUND_NOISE: 'excessive_background_noise',\n    MICROPHONE_COVERED: 'microphone_covered',\n    EXTERNAL_DEVICE: 'external_device_detected',\n    COMMUNICATION_DETECTED: 'communication_detected',\n    UNUSUAL_SILENCE: 'unusual_silence_pattern',\n    KEYBOARD_TYPING: 'excessive_keyboard_typing',\n    PHONE_RINGING: 'phone_ringing_detected'\n  };\n\n  // Audio thresholds for different security levels\n  const AUDIO_THRESHOLDS = {\n    1: { // Basic\n      voiceThreshold: 0.3,\n      backgroundNoiseThreshold: 0.5,\n      silenceThreshold: 0.05\n    },\n    2: { // Standard\n      voiceThreshold: 0.2,\n      backgroundNoiseThreshold: 0.4,\n      silenceThreshold: 0.03\n    },\n    3: { // High\n      voiceThreshold: 0.15,\n      backgroundNoiseThreshold: 0.3,\n      silenceThreshold: 0.02\n    },\n    4: { // Maximum\n      voiceThreshold: 0.1,\n      backgroundNoiseThreshold: 0.2,\n      silenceThreshold: 0.01\n    }\n  };\n\n  // Log violation with cooldown\n  const logViolation = useCallback((type, details = {}) => {\n    if (violationCooldownRef.current.has(type)) return;\n    \n    violationCooldownRef.current.add(type);\n    setTimeout(() => violationCooldownRef.current.delete(type), 5000);\n\n    const violation = {\n      id: `${type}-${Date.now()}`,\n      type,\n      timestamp: new Date().toISOString(),\n      examId,\n      studentId,\n      details,\n      severity: getViolationSeverity(type)\n    };\n\n    setViolations(prev => [...prev, violation]);\n    onViolation && onViolation(violation);\n\n    // Show notification based on severity and security level\n    const message = getViolationMessage(type);\n    if (violation.severity === 'critical') {\n      toast.error(`üîä ${message}`);\n    } else if (violation.severity === 'major' && securityLevel >= 2) {\n      toast.warn(`‚ö†Ô∏è ${message}`);\n    } else if (securityLevel >= 3) {\n      toast.info(`‚ÑπÔ∏è ${message}`);\n    }\n  }, [examId, studentId, onViolation, securityLevel]);\n\n  // Get violation severity\n  const getViolationSeverity = (type) => {\n    switch (type) {\n      case VIOLATION_TYPES.MULTIPLE_VOICES:\n      case VIOLATION_TYPES.COMMUNICATION_DETECTED:\n      case VIOLATION_TYPES.EXTERNAL_DEVICE:\n        return 'critical';\n      case VIOLATION_TYPES.VOICE_DETECTED:\n      case VIOLATION_TYPES.SUSPICIOUS_SOUND:\n      case VIOLATION_TYPES.BACKGROUND_NOISE:\n        return 'major';\n      default:\n        return 'minor';\n    }\n  };\n\n  // Get violation message\n  const getViolationMessage = (type) => {\n    switch (type) {\n      case VIOLATION_TYPES.VOICE_DETECTED:\n        return 'Speaking detected. Please remain silent during the exam.';\n      case VIOLATION_TYPES.MULTIPLE_VOICES:\n        return 'Multiple voices detected! Only you should be present.';\n      case VIOLATION_TYPES.SUSPICIOUS_SOUND:\n        return 'Suspicious sound detected. Please minimize noise.';\n      case VIOLATION_TYPES.BACKGROUND_NOISE:\n        return 'High background noise detected. Please find a quieter location.';\n      case VIOLATION_TYPES.MICROPHONE_COVERED:\n        return 'Microphone appears to be covered or muted.';\n      case VIOLATION_TYPES.EXTERNAL_DEVICE:\n        return 'External communication device detected.';\n      case VIOLATION_TYPES.COMMUNICATION_DETECTED:\n        return 'Communication with another person detected.';\n      case VIOLATION_TYPES.UNUSUAL_SILENCE:\n        return 'Unusual silence pattern detected.';\n      case VIOLATION_TYPES.KEYBOARD_TYPING:\n        return 'Excessive typing detected outside of exam responses.';\n      case VIOLATION_TYPES.PHONE_RINGING:\n        return 'Phone ringing detected. Please silence all devices.';\n      default:\n        return 'Audio monitoring violation detected.';\n    }\n  };\n\n  // Initialize microphone\n  const initializeMicrophone = useCallback(async () => {\n    try {\n      const mediaStream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: true,\n          noiseSuppression: false, // We want to detect background noise\n          autoGainControl: false,\n          sampleRate: 44100\n        }\n      });\n      \n      setStream(mediaStream);\n      setMicrophonePermission('granted');\n      \n      // Initialize Web Audio API\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      microphoneRef.current = audioContextRef.current.createMediaStreamSource(mediaStream);\n      \n      // Configure analyser\n      analyserRef.current.fftSize = 2048;\n      analyserRef.current.smoothingTimeConstant = 0.8;\n      \n      // Connect microphone to analyser\n      microphoneRef.current.connect(analyserRef.current);\n      \n      // Initialize audio data array\n      audioDataRef.current = new Uint8Array(analyserRef.current.frequencyBinCount);\n      \n      setIsInitialized(true);\n      startMonitoring();\n      \n    } catch (error) {\n      console.error('Microphone initialization failed:', error);\n      setMicrophonePermission('denied');\n      toast.error('Microphone access required for exam proctoring.');\n      \n      logViolation(VIOLATION_TYPES.MICROPHONE_COVERED, {\n        error: error.message,\n        name: error.name\n      });\n    }\n  }, [logViolation]);\n\n  // Start audio monitoring\n  const startMonitoring = useCallback(() => {\n    const monitor = () => {\n      if (!isActive || !analyserRef.current) {\n        animationRef.current = requestAnimationFrame(monitor);\n        return;\n      }\n\n      try {\n        analyseAudio();\n        detectViolations();\n      } catch (error) {\n        console.error('Audio monitoring error:', error);\n      }\n\n      animationRef.current = requestAnimationFrame(monitor);\n    };\n\n    monitor();\n  }, [isActive]);\n\n  // Analyze audio data\n  const analyseAudio = useCallback(() => {\n    if (!analyserRef.current) return;\n\n    // Get frequency data\n    analyserRef.current.getByteFrequencyData(audioDataRef.current);\n    \n    // Calculate volume (RMS)\n    let sum = 0;\n    for (let i = 0; i < audioDataRef.current.length; i++) {\n      sum += audioDataRef.current[i] * audioDataRef.current[i];\n    }\n    const volume = Math.sqrt(sum / audioDataRef.current.length) / 255;\n    \n    // Calculate dominant frequency\n    let maxAmplitude = 0;\n    let dominantFrequency = 0;\n    for (let i = 0; i < audioDataRef.current.length; i++) {\n      if (audioDataRef.current[i] > maxAmplitude) {\n        maxAmplitude = audioDataRef.current[i];\n        dominantFrequency = i * (audioContextRef.current.sampleRate / 2) / audioDataRef.current.length;\n      }\n    }\n    \n    // Voice detection (human voice typically 85-300 Hz fundamental)\n    const isVoiceDetected = detectVoice(audioDataRef.current, volume);\n    const voiceCount = countVoices(audioDataRef.current);\n    const backgroundNoise = calculateBackgroundNoise(audioDataRef.current);\n    const suspiciousActivity = detectSuspiciousAudio(audioDataRef.current, dominantFrequency);\n    \n    // Update audio data\n    const newAudioData = {\n      volume: Math.round(volume * 100) / 100,\n      frequency: Math.round(dominantFrequency),\n      isVoiceDetected,\n      backgroundNoise: Math.round(backgroundNoise * 100) / 100,\n      suspiciousActivity,\n      voiceCount,\n      silenceLevel: volume < 0.01 ? 1 : 0\n    };\n    \n    setAudioData(newAudioData);\n    \n    // Update audio history for pattern analysis\n    audioHistoryRef.current.push(newAudioData);\n    if (audioHistoryRef.current.length > 100) {\n      audioHistoryRef.current.shift();\n    }\n    \n    // Update voice detection tracking\n    updateVoiceTracking(isVoiceDetected, volume);\n    \n  }, []);\n\n  // Detect human voice patterns\n  const detectVoice = useCallback((frequencyData, volume) => {\n    const threshold = AUDIO_THRESHOLDS[securityLevel]?.voiceThreshold || 0.2;\n    \n    if (volume < threshold) return false;\n    \n    // Analyze frequency spectrum for voice characteristics\n    let voiceFrequencyEnergy = 0;\n    let totalEnergy = 0;\n    \n    // Human voice fundamental frequency range (roughly 85-300 Hz)\n    const voiceStartBin = Math.floor(85 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    const voiceEndBin = Math.floor(300 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    \n    for (let i = 0; i < frequencyData.length; i++) {\n      const energy = frequencyData[i] * frequencyData[i];\n      totalEnergy += energy;\n      \n      if (i >= voiceStartBin && i <= voiceEndBin) {\n        voiceFrequencyEnergy += energy;\n      }\n    }\n    \n    // Voice detected if significant energy in voice frequency range\n    const voiceRatio = totalEnergy > 0 ? voiceFrequencyEnergy / totalEnergy : 0;\n    return voiceRatio > 0.3 && volume > threshold;\n  }, [securityLevel]);\n\n  // Count number of voices (simplified approach)\n  const countVoices = useCallback((frequencyData) => {\n    // This is a simplified voice counting algorithm\n    // In production, you'd use more sophisticated audio processing\n    \n    let peakCount = 0;\n    const peaks = [];\n    \n    // Find peaks in frequency spectrum\n    for (let i = 1; i < frequencyData.length - 1; i++) {\n      if (frequencyData[i] > frequencyData[i-1] && \n          frequencyData[i] > frequencyData[i+1] && \n          frequencyData[i] > 50) {\n        peaks.push({ frequency: i, amplitude: frequencyData[i] });\n        peakCount++;\n      }\n    }\n    \n    // Estimate voice count based on peak distribution\n    // Multiple distinct peaks in voice range might indicate multiple speakers\n    const voiceRangePeaks = peaks.filter(peak => {\n      const freq = peak.frequency * (audioContextRef.current.sampleRate / 2) / frequencyData.length;\n      return freq >= 85 && freq <= 300;\n    });\n    \n    return Math.min(voiceRangePeaks.length > 3 ? 2 : 1, peakCount > 0 ? 1 : 0);\n  }, []);\n\n  // Calculate background noise level\n  const calculateBackgroundNoise = useCallback((frequencyData) => {\n    // Calculate energy in non-voice frequencies\n    let backgroundEnergy = 0;\n    let sampleCount = 0;\n    \n    const voiceStartBin = Math.floor(85 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    const voiceEndBin = Math.floor(300 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    \n    for (let i = 0; i < frequencyData.length; i++) {\n      if (i < voiceStartBin || i > voiceEndBin) {\n        backgroundEnergy += frequencyData[i];\n        sampleCount++;\n      }\n    }\n    \n    return sampleCount > 0 ? (backgroundEnergy / sampleCount) / 255 : 0;\n  }, []);\n\n  // Detect suspicious audio patterns\n  const detectSuspiciousAudio = useCallback((frequencyData, dominantFrequency) => {\n    // Check for phone rings (typically around 400-800 Hz)\n    if (dominantFrequency >= 400 && dominantFrequency <= 800) {\n      return 'phone_ring';\n    }\n    \n    // Check for keyboard typing patterns (high frequency clicks)\n    let highFreqEnergy = 0;\n    const highFreqStart = Math.floor(2000 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    const highFreqEnd = Math.floor(8000 * frequencyData.length / (audioContextRef.current.sampleRate / 2));\n    \n    for (let i = highFreqStart; i < Math.min(highFreqEnd, frequencyData.length); i++) {\n      highFreqEnergy += frequencyData[i];\n    }\n    \n    if (highFreqEnergy > 1000) {\n      return 'keyboard_typing';\n    }\n    \n    return false;\n  }, []);\n\n  // Update voice tracking data\n  const updateVoiceTracking = useCallback((isVoiceDetected, volume) => {\n    const now = Date.now();\n    const tracking = voiceDetectionRef.current;\n    \n    if (isVoiceDetected) {\n      if (tracking.lastVoiceTime === 0) {\n        tracking.lastVoiceTime = now;\n      }\n      tracking.voiceDuration = now - tracking.lastVoiceTime;\n      tracking.silenceDuration = 0;\n    } else {\n      if (tracking.lastVoiceTime > 0) {\n        tracking.silenceDuration = now - (tracking.lastVoiceTime + tracking.voiceDuration);\n      }\n    }\n    \n    tracking.avgAmplitude = (tracking.avgAmplitude * 0.9) + (volume * 0.1);\n  }, []);\n\n  // Detect violations based on audio analysis\n  const detectViolations = useCallback(() => {\n    const { isVoiceDetected, voiceCount, backgroundNoise, suspiciousActivity, volume } = audioData;\n    const threshold = AUDIO_THRESHOLDS[securityLevel] || AUDIO_THRESHOLDS[2];\n    \n    // Voice detection violation\n    if (isVoiceDetected && securityLevel >= 1) {\n      logViolation(VIOLATION_TYPES.VOICE_DETECTED, {\n        volume,\n        duration: voiceDetectionRef.current.voiceDuration,\n        timestamp: Date.now()\n      });\n    }\n    \n    // Multiple voices violation\n    if (voiceCount > 1 && securityLevel >= 2) {\n      logViolation(VIOLATION_TYPES.MULTIPLE_VOICES, {\n        voiceCount,\n        timestamp: Date.now()\n      });\n    }\n    \n    // Background noise violation\n    if (backgroundNoise > threshold.backgroundNoiseThreshold) {\n      logViolation(VIOLATION_TYPES.BACKGROUND_NOISE, {\n        level: backgroundNoise,\n        threshold: threshold.backgroundNoiseThreshold\n      });\n    }\n    \n    // Suspicious activity violations\n    if (suspiciousActivity) {\n      switch (suspiciousActivity) {\n        case 'phone_ring':\n          logViolation(VIOLATION_TYPES.PHONE_RINGING, {\n            detected: true,\n            timestamp: Date.now()\n          });\n          break;\n        case 'keyboard_typing':\n          if (securityLevel >= 3) {\n            logViolation(VIOLATION_TYPES.KEYBOARD_TYPING, {\n              detected: true,\n              timestamp: Date.now()\n            });\n          }\n          break;\n      }\n    }\n    \n    // Microphone covered/muted check\n    if (volume < threshold.silenceThreshold && audioHistoryRef.current.length > 50) {\n      const recentSilence = audioHistoryRef.current.slice(-50).every(data => data.volume < threshold.silenceThreshold);\n      if (recentSilence) {\n        logViolation(VIOLATION_TYPES.MICROPHONE_COVERED, {\n          silenceDuration: 5000, // 50 frames * 100ms per frame\n          threshold: threshold.silenceThreshold\n        });\n      }\n    }\n    \n  }, [audioData, logViolation, securityLevel]);\n\n  // Initialize when component becomes active\n  useEffect(() => {\n    if (isActive && !isInitialized) {\n      initializeMicrophone();\n    }\n    \n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [isActive, isInitialized, initializeMicrophone]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      if (stream) {\n        stream.getTracks().forEach(track => track.stop());\n      }\n      if (audioContextRef.current) {\n        audioContextRef.current.close();\n      }\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [stream]);\n\n  if (!isActive) {\n    return null;\n  }\n\n  return (\n    <div className=\"audio-monitoring-container\">\n      {/* Microphone permission prompt */}\n      {microphonePermission === 'prompt' && (\n        <div className=\"microphone-permission-prompt\">\n          <div className=\"permission-content\">\n            <h3>üé§ Microphone Access Required</h3>\n            <p>This exam requires microphone access for audio monitoring and security.</p>\n            <button className=\"permission-btn\" onClick={initializeMicrophone}>\n              Grant Microphone Access\n            </button>\n          </div>\n        </div>\n      )}\n      \n      {/* Microphone denied message */}\n      {microphonePermission === 'denied' && (\n        <div className=\"microphone-denied\">\n          <div className=\"denied-content\">\n            <h3>‚ùå Microphone Access Denied</h3>\n            <p>Microphone access is required to proceed with the exam. Please enable microphone access and refresh the page.</p>\n            <button className=\"retry-btn\" onClick={initializeMicrophone}>\n              Retry Microphone Access\n            </button>\n          </div>\n        </div>\n      )}\n      \n      {/* Audio monitoring status */}\n      {isInitialized && microphonePermission === 'granted' && (\n        <div className=\"audio-status\">\n          {/* Volume indicator */}\n          <div className=\"audio-indicator\">\n            <span className=\"audio-icon\">üé§</span>\n            <div className=\"audio-info\">\n              <div className=\"volume-bar\">\n                <div \n                  className=\"volume-fill\"\n                  style={{ width: `${audioData.volume * 100}%` }}\n                />\n              </div>\n              <div className=\"audio-details\">\n                <span className=\"volume-text\">Vol: {Math.round(audioData.volume * 100)}%</span>\n                {securityLevel >= 2 && (\n                  <span className=\"noise-text\">Noise: {Math.round(audioData.backgroundNoise * 100)}%</span>\n                )}\n              </div>\n            </div>\n          </div>\n          \n          {/* Voice detection indicator */}\n          {securityLevel >= 2 && (\n            <div className={`voice-indicator ${audioData.isVoiceDetected ? 'detected' : 'silent'}`}>\n              <span className=\"voice-icon\">\n                {audioData.isVoiceDetected ? 'üó£Ô∏è' : 'üîá'}\n              </span>\n              <div className=\"voice-status\">\n                {audioData.isVoiceDetected ? 'Voice Detected' : 'Silent'}\n                {audioData.voiceCount > 1 && (\n                  <span className=\"voice-count\"> ({audioData.voiceCount} voices)</span>\n                )}\n              </div>\n            </div>\n          )}\n          \n          {/* Suspicious activity indicator */}\n          {audioData.suspiciousActivity && securityLevel >= 3 && (\n            <div className=\"suspicious-indicator\">\n              <span className=\"suspicious-icon\">‚ö†Ô∏è</span>\n              <div className=\"suspicious-text\">\n                {audioData.suspiciousActivity.replace('_', ' ').toUpperCase()}\n              </div>\n            </div>\n          )}\n        </div>\n      )}\n      \n      {/* Audio visualization (development mode) */}\n      {process.env.NODE_ENV === 'development' && isInitialized && (\n        <div className=\"audio-visualization\">\n          <canvas \n            ref={(canvas) => {\n              if (canvas && analyserRef.current) {\n                const ctx = canvas.getContext('2d');\n                const width = canvas.width = 300;\n                const height = canvas.height = 100;\n                \n                const draw = () => {\n                  if (!analyserRef.current) return;\n                  \n                  analyserRef.current.getByteFrequencyData(audioDataRef.current);\n                  \n                  ctx.fillStyle = 'rgb(0, 0, 0)';\n                  ctx.fillRect(0, 0, width, height);\n                  \n                  const barWidth = width / audioDataRef.current.length * 2.5;\n                  let barHeight;\n                  let x = 0;\n                  \n                  for (let i = 0; i < audioDataRef.current.length; i++) {\n                    barHeight = audioDataRef.current[i] / 255 * height;\n                    \n                    ctx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;\n                    ctx.fillRect(x, height - barHeight, barWidth, barHeight);\n                    \n                    x += barWidth + 1;\n                  }\n                  \n                  requestAnimationFrame(draw);\n                };\n                \n                draw();\n              }\n            }}\n          />\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default AudioMonitoring;